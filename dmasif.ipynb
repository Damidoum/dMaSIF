{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8be7ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create folder for the pdbs\n",
    "pred_dir = '/home/onyxia/work/pdbs'\n",
    "isExist = os.path.exists(pred_dir)\n",
    "if not isExist:\n",
    "  os.makedirs(pred_dir)\n",
    "\n",
    "def get_pdb(pdb_code=\"\"):\n",
    "  \"\"\"Taken from the Afdesign notebook by Sergey Ovchinnikov.\"\"\"\n",
    "  if pdb_code is None or pdb_code == \"\":\n",
    "    upload_dict = files.upload()\n",
    "    pdb_string = upload_dict[list(upload_dict.keys())[0]]\n",
    "    with open(\"tmp.pdb\",\"wb\") as out: out.write(pdb_string)\n",
    "    return \"tmp.pdb\"\n",
    "  else:\n",
    "    os.system(f\"wget -qnc -O /home/onyxia/work/pdbs/{pdb_code}.pdb https://files.rcsb.org/view/{pdb_code}.pdb \")\n",
    "\n",
    "#@markdown Or download a PDB directly from the Protein DataBank (PDB).\n",
    "target_pdb = \"1NPU\" #@param {type:\"string\"}\n",
    "get_pdb(target_pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1beb11a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# target pdb\n",
    "target_pdb = \"/home/onyxia/work/pdbs/1NPU.pdb\"\n",
    "target_name = target_pdb.split('/')\n",
    "target_name = target_name[-1].split('.')\n",
    "\n",
    "if target_name[-1] == 'pdb':\n",
    "  target_name = target_name[0]\n",
    "else:\n",
    "  print('Please upload a valid .pdb file!')\n",
    "\n",
    "chain_name = 'A' #@param {type:\"string\"}\n",
    "chains = [chain_name]\n",
    "\n",
    "# Path to MaSIF weights\n",
    "model_resolution = '0.7 Angstrom' #@param [\"1 Angstrom\", \"0.7 Angstrom\"]\n",
    "patch_radius = '9 Angstrom' #@param [\"9 Angstrom\", \"12 Angstrom\"]\n",
    "\n",
    "\n",
    "if patch_radius == '9 Angstrom':\n",
    "  if model_resolution == '1 Angstrom':\n",
    "    model_path = '/home/onyxia/work/MaSIF_colab/models/dMaSIF_site_3layer_16dims_9A_100sup_epoch64'\n",
    "    resolution = 1.0\n",
    "    radius = 9\n",
    "    sup_sampling = 100\n",
    "  else:\n",
    "    model_path = '/home/onyxia/work/MaSIF_colab/models/dMaSIF_site_3layer_16dims_9A_0.7res_150sup_epoch85'\n",
    "    resolution = 0.7\n",
    "    radius = 9\n",
    "    supsampling = 150\n",
    "\n",
    "elif patch_radius == '12 Angstrom':\n",
    "  if model_resolution == '1 Angstrom':\n",
    "    model_path = '/home/onyxia/work/MaSIF_colab/models/dMaSIF_site_3layer_16dims_12A_100sup_epoch71'\n",
    "    resolution = 1.0\n",
    "    radius = 12\n",
    "    supsampling = 100\n",
    "  else:\n",
    "    model_path = '/home/onyxia/work/MaSIF_colab/models/dMaSIF_site_3layer_16dims_12A_0.7res_150sup_epoch59'\n",
    "    resolution = 0.7\n",
    "    radius = 12\n",
    "    supsampling = 100\n",
    "\n",
    "\n",
    "# create new folders\n",
    "# chain dir\n",
    "chains_dir = '/home/onyxia/work/chains'\n",
    "isExist = os.path.exists(chains_dir)\n",
    "if not isExist:\n",
    "  os.makedirs(chains_dir)\n",
    "else:\n",
    "  files = glob.glob(chains_dir + '/*')\n",
    "  for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "# npy folder\n",
    "npy_dir = '/home/onyxia/work/npys'\n",
    "isExist = os.path.exists(npy_dir)\n",
    "if not isExist:\n",
    "  os.makedirs(npy_dir)\n",
    "else:\n",
    "  files = glob.glob(npy_dir + '/*')\n",
    "  for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "# Create folder for the embeddings\n",
    "pred_dir = '/home/onyxia/work/preds'\n",
    "isExist = os.path.exists(pred_dir)\n",
    "if not isExist:\n",
    "  os.makedirs(pred_dir)\n",
    "else:\n",
    "  files = glob.glob(pred_dir + '/*')\n",
    "  for f in files:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d00319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a26e04df6f84cc3a7798731180237e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Load functions\n",
    "import sys\n",
    "sys.path.append(\"MaSIF_colab\") \n",
    "sys.path.append(\"MaSIF_colab/data_preprocessing\") \n",
    "sys.path.append(\"data_preprocessing\")\n",
    "\n",
    "import numpy as np\n",
    "import pykeops\n",
    "import torch\n",
    "from Bio.PDB import *\n",
    "from data_preprocessing import download_pdb\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.transforms import Compose\n",
    "import argparse\n",
    "import shutil\n",
    "\n",
    "# Custom data loader and model:\n",
    "from data import ProteinPairsSurfaces, PairData, CenterPairAtoms, load_protein_pair\n",
    "from data import RandomRotationPairAtoms, NormalizeChemFeatures, iface_valid_filter\n",
    "from model import dMaSIF\n",
    "from data_iteration import iterate\n",
    "from helper import *\n",
    "\n",
    "#import ipywidgets as widgets\n",
    "import nglview as ng\n",
    "#import ipywidgets as widgets\n",
    "from pdbparser.pdbparser import pdbparser\n",
    "\n",
    "def generate_descr(model_path, output_path, pdb_file, npy_directory, radius, resolution,supsampling):\n",
    "    \"\"\"Generat descriptors for a MaSIF site model\"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Network parameters\")\n",
    "    parser.add_argument(\"--experiment_name\", type=str, default=model_path)\n",
    "    parser.add_argument(\"--use_mesh\", type=bool, default=False)\n",
    "    parser.add_argument(\"--embedding_layer\",type=str,default=\"dMaSIF\")\n",
    "    parser.add_argument(\"--curvature_scales\",type=list,default=[1.0, 2.0, 3.0, 5.0, 10.0])\n",
    "    parser.add_argument(\"--resolution\",type=float,default=resolution)\n",
    "    parser.add_argument(\"--distance\",type=float,default=1.05)\n",
    "    parser.add_argument(\"--variance\",type=float,default=0.1)\n",
    "    parser.add_argument(\"--sup_sampling\", type=int, default=supsampling)\n",
    "    parser.add_argument(\"--atom_dims\",type=int,default=6)\n",
    "    parser.add_argument(\"--emb_dims\",type=int,default=16)\n",
    "    parser.add_argument(\"--in_channels\",type=int,default=16)\n",
    "    parser.add_argument(\"--orientation_units\",type=int,default=16)\n",
    "    parser.add_argument(\"--unet_hidden_channels\",type=int,default=8)\n",
    "    parser.add_argument(\"--post_units\",type=int,default=8)\n",
    "    parser.add_argument(\"--n_layers\", type=int, default=3)\n",
    "    parser.add_argument(\"--radius\", type=float, default=radius)\n",
    "    parser.add_argument(\"--k\",type=int,default=40)\n",
    "    parser.add_argument(\"--dropout\",type=float,default=0.0)\n",
    "    parser.add_argument(\"--site\", type=bool, default=True) # set to true for site model\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=1)\n",
    "    parser.add_argument(\"--search\",type=bool,default=False) # Set to true for search model\n",
    "    parser.add_argument(\"--single_pdb\",type=str,default=pdb_file)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--random_rotation\",type=bool,default=False)\n",
    "    parser.add_argument(\"--device\", type=str, default=\"cpu\")\n",
    "    #parser.add_argument(\"--single_protein\",type=bool,default=True)\n",
    "    parser.add_argument(\"--single_protein\",type=bool,default=True) # set to false for site\n",
    "    parser.add_argument(\"--no_chem\", type=bool, default=False)\n",
    "    parser.add_argument(\"--no_geom\", type=bool, default=False)\n",
    "    \n",
    "    args = parser.parse_args(\"\")\n",
    "\n",
    "    model_path = args.experiment_name\n",
    "    save_predictions_path = Path(output_path)\n",
    "    \n",
    "    # Ensure reproducability:\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "\n",
    "    # Load the train and test datasets:\n",
    "    transformations = (\n",
    "        Compose([NormalizeChemFeatures(), CenterPairAtoms(), RandomRotationPairAtoms()])\n",
    "        if args.random_rotation\n",
    "        else Compose([NormalizeChemFeatures()])\n",
    "    )\n",
    "    \n",
    "    if args.single_pdb != \"\":\n",
    "        single_data_dir = Path(npy_directory)\n",
    "        test_dataset = [load_protein_pair(args.single_pdb, single_data_dir, single_pdb=True)]\n",
    "        test_pdb_ids = [args.single_pdb]\n",
    "\n",
    "    # PyTorch geometric expects an explicit list of \"batched variables\":\n",
    "    batch_vars = [\"xyz_p1\", \"xyz_p2\", \"atom_coords_p1\", \"atom_coords_p2\"]\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=args.batch_size, follow_batch=batch_vars\n",
    "    )\n",
    "\n",
    "    net = dMaSIF(args)\n",
    "    # net.load_state_dict(torch.load(model_path, map_location=args.device))\n",
    "    net.load_state_dict(torch.load(model_path, map_location=args.device)[\"model_state_dict\"])\n",
    "    net = net.to(args.device)\n",
    "\n",
    "    # Perform one pass through the data:\n",
    "    info = iterate(\n",
    "        net,\n",
    "        test_loader,\n",
    "        None,\n",
    "        args,\n",
    "        test=True,\n",
    "        save_path=save_predictions_path,\n",
    "        pdb_ids=test_pdb_ids,\n",
    "    )\n",
    "    return info\n",
    "\n",
    "  \n",
    "\n",
    "def show_pointcloud(main_pdb, coord_file, emb_file):\n",
    "  # Normalize embedding to represent a b-factor value between 0-100\n",
    "  b_factor = []\n",
    "  for emb in emb_file:\n",
    "      b_factor.append(emb[-2])\n",
    "  \n",
    "  # b_factor = [(float(i)-min(b_factor))/(max(b_factor)-min(b_factor)) for i in b_factor]\n",
    "\n",
    "  # writing a psudo pdb of all points using their coordinates and H atom.\n",
    "  records = []\n",
    "\n",
    "  for i in range(len(coord_file)):\n",
    "      points = coord_file[i]\n",
    "      x_coord = points[0]\n",
    "      y_coord = points[1]\n",
    "      z_coord = points[2]\n",
    "\n",
    "      records.append( { \"record_name\"       : 'ATOM',\n",
    "                    \"serial_number\"     : len(records)+1,\n",
    "                    \"atom_name\"         : 'H',\n",
    "                    \"location_indicator\": '',\n",
    "                    \"residue_name\"      : 'XYZ',\n",
    "                    \"chain_identifier\"  : '',\n",
    "                    \"sequence_number\"   : len(records)+1,\n",
    "                    \"code_of_insertion\" : '',\n",
    "                    \"coordinates_x\"     : x_coord,\n",
    "                    \"coordinates_y\"     : y_coord,\n",
    "                    \"coordinates_z\"     : z_coord,\n",
    "                    \"occupancy\"         : 1.0,\n",
    "                    \"temperature_factor\": b_factor[i]*100,\n",
    "                    \"segment_identifier\": '',\n",
    "                    \"element_symbol\"    : 'H',\n",
    "                    \"charge\"            : '',\n",
    "                    } )\n",
    "    \n",
    "  pdb = pdbparser()\n",
    "  pdb.records = records\n",
    "\n",
    "  pdb.export_pdb(\"pointcloud.pdb\")\n",
    "\n",
    "  # reading the psudo PDB we generated above for the point cloud.\n",
    "  coordPDB = \"pointcloud.pdb\"\n",
    "  view = ng.NGLWidget()\n",
    "  view.add_component(ng.FileStructure(os.path.join(\"/home/onyxia/work/MaSIF_colab\", coordPDB)), defaultRepresentation=False)\n",
    "\n",
    "  # representation with our customized colorscheme.\n",
    "  view.add_representation('point', \n",
    "                          useTexture = 1,\n",
    "                          pointSize = 2,\n",
    "                          colorScheme = \"bfactor\",\n",
    "                          colorDomain = [100.0, 0.0], \n",
    "                          colorScale = 'rwb',\n",
    "                          selection='_H')\n",
    "\n",
    "  view.add_component(ng.FileStructure(os.path.join(\"/home/onyxia/work\", main_pdb)))\n",
    "  view.background = 'black'\n",
    "  return view\n",
    "\n",
    "def show_structure(main_pdb):\n",
    "  # reading the psudo PDB we generated above for the point cloud.\n",
    "  view = ng.NGLWidget()\n",
    "\n",
    "  view.add_component(ng.FileStructure(main_pdb), defaultRepresentation=False)\n",
    "  view.add_representation(\"cartoon\", colorScheme = \"bfactor\", colorScale = 'rwb', colorDomain = [100.0, 0.0])\n",
    "  view.add_representation(\"ball+stick\", colorScheme = \"bfactor\", colorScale = 'rwb', colorDomain = [100.0, 0.0])\n",
    "  view.background = 'black'\n",
    "  return view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea37340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.74s/it]\n"
     ]
    }
   ],
   "source": [
    "#@title Run MaSIF\n",
    "# Protonate the pdb file using reduce\n",
    "tmp_pdb = '/home/onyxia/work/pdbs/tmp_1.pdb'\n",
    "shutil.copyfile(target_pdb, tmp_pdb)\n",
    "\n",
    "# Remove protons if there are any\n",
    "!reduce -Trim -Quiet /home/onyxia/work/pdbs/tmp_1.pdb > /home/onyxia/work/pdbs/tmp_2.pdb\n",
    "# Add protons\n",
    "!reduce -HIS -Quiet /home/onyxia/work/pdbs/tmp_2.pdb > /home/onyxia/work/pdbs/tmp_3.pdb\n",
    "\n",
    "tmp_pdb = '/home/onyxia/work/pdbs/tmp_3.pdb'\n",
    "shutil.copyfile(tmp_pdb, target_pdb)\n",
    "\n",
    "# Generate the surface features\n",
    "download_pdb.convert_to_npy(target_pdb, chains_dir, npy_dir, chains)\n",
    "\n",
    "# Generate the embeddings\n",
    "pdb_name = \"{n}_{c}_{c}\".format(n= target_name, c=chain_name)\n",
    "info = generate_descr(model_path, pred_dir, pdb_name, npy_dir, radius, resolution, supsampling)\n",
    "\n",
    "# In info I hardcoded memory usage to 0 so MaSIF would run on the CPU. We might want to change this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217b50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Generate PDBs for hotspot atoms and residues\n",
    "list_hotspot_residues = False #@param {type:\"boolean\"}\n",
    "\n",
    "from Bio.PDB.PDBParser import PDBParser\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "parser=PDBParser(PERMISSIVE=1)\n",
    "structure=parser.get_structure(\"structure\", target_pdb)\n",
    "\n",
    "coord = np.load(\"/home/onyxia/work/preds/{n}_{c}_predcoords.npy\".format(n= target_name, c=chain_name))\n",
    "embedding = np.load(\"/home/onyxia/work/preds/{n}_{c}_predfeatures_emb1.npy\".format(n= target_name, c=chain_name))\n",
    "atom_coords = np.stack([atom.get_coord() for atom in structure.get_atoms()])\n",
    "\n",
    "b_factor = embedding[:, -2]\n",
    "# b_factor = (b_factor - min(b_factor)) / (max(b_factor) - min(b_factor))\n",
    "\n",
    "dists = cdist(atom_coords, coord)\n",
    "nn_ind = np.argmin(dists, axis=1)\n",
    "dists = dists[np.arange(len(dists)), nn_ind]\n",
    "atom_b_factor = b_factor[nn_ind]\n",
    "dist_thresh = 2.0\n",
    "atom_b_factor[dists > dist_thresh] = 0.0\n",
    "\n",
    "for i, atom in enumerate(structure.get_atoms()):\n",
    "    atom.set_bfactor(atom_b_factor[i] * 100)\n",
    "\n",
    "# Create folder for the embeddings\n",
    "pred_dir = '/home/onyxia/work/output'\n",
    "os.makedirs(pred_dir, exist_ok=True)\n",
    "\n",
    "# Save pdb file with per-atom b-factors\n",
    "io = PDBIO()\n",
    "io.set_structure(structure)\n",
    "io.save(\"/home/onyxia/work/output/per_atom_binding.pdb\")\n",
    "\n",
    "atom_residues = np.array([atom.get_parent().id[1] for atom in structure.get_atoms()])\n",
    "\n",
    "hotspot_res = {}\n",
    "for residue in structure.get_residues():\n",
    "    res_id = residue.id[1]\n",
    "    res_b_factor = np.max(atom_b_factor[atom_residues == res_id])\n",
    "    hotspot_res[res_id] = res_b_factor\n",
    "    for atom in residue.get_atoms():\n",
    "        atom.set_bfactor(res_b_factor * 100)\n",
    "\n",
    "# Save pdb file with per-residue b-factors\n",
    "io = PDBIO()\n",
    "io.set_structure(structure)\n",
    "io.save(\"/home/onyxia/work/output/per_resi_binding.pdb\")\n",
    "\n",
    "if list_hotspot_residues:\n",
    "  print('Sorted on residue contribution (high to low')\n",
    "  for w in sorted(hotspot_res, key=hotspot_res.get, reverse=True):\n",
    "    print(w, hotspot_res[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e38887d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29 16:34:04 - pdbparser <INFO> All records successfully exported to 'pointcloud.pdb'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35dd79b7d69d4d498f5dd717c6888648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget(background='black')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Plot output\n",
    "#@markdown Blue identifies non-binding and red identifies binding interaction sites. Rerun this cell if you want to change the plotted structure.\n",
    "plot_structure = 'Pointcloud' #@param [\"Pointcloud\", \"Residues\", \"Atoms\"]\n",
    "\n",
    "## file addresses\n",
    "if plot_structure == 'Pointcloud':\n",
    "  view = show_pointcloud(target_pdb, coord, embedding)\n",
    "elif plot_structure == \"Residues\":\n",
    "  view = show_structure('/home/onyxia/work/output/per_resi_binding.pdb')\n",
    "elif plot_structure == \"Atoms\":\n",
    "  view = show_structure('/home/onyxia/work/output/per_atom_binding.pdb')\n",
    "\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba2e098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmasif",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
